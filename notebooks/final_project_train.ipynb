{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project - Gregory LeMasurier and Mojtaba Talaei Khoei\n",
    "\n",
    "Making the training file a jupyter notebook for the time being so I can easily debug it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge-score in /home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages (0.0.4)\n",
      "Requirement already satisfied: nltk in /home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages (3.7)\n",
      "Requirement already satisfied: sentencepiece in /home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages (0.1.96)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: numpy in /home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages (from rouge-score) (1.21.5)\n",
      "Requirement already satisfied: absl-py in /home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages (from rouge-score) (1.0.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages (from nltk) (2022.1.18)\n",
      "Requirement already satisfied: click in /home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: tqdm in /home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: joblib in /home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages (from click->nltk) (4.10.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Install Dependencies\n",
    "import sys\n",
    "!{sys.executable} -m pip install rouge-score nltk sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Imports\n",
    "import os\n",
    "import random\n",
    "\n",
    "import transformers\n",
    "from transformers import PegasusTokenizer, PegasusConfig\n",
    "from transformers import PegasusForConditionalGeneration\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import wandb\n",
    "from packaging import version\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from transformer_mt import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"Summarization\")\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "datasets.utils.logging.set_verbosity_warning()\n",
    "transformers.utils.logging.set_verbosity_warning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE Metric\n",
    "rouge = datasets.load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_only = True\n",
    "\n",
    "dataset_name = 'cnn_dailymail'\n",
    "dataset_version = '3.0.0'\n",
    "wandb_project = \"PegasusSummarization\"\n",
    "output_dir = \"output_dir/\"\n",
    "device = 'cuda' if (torch.cuda.is_available() and not cpu_only) else 'cpu'\n",
    "\n",
    "if torch.cuda.is_available:\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "model_name = 'google/pegasus-xsum' \n",
    "tokenizer_name = 'google/pegasus-cnn_dailymail'\n",
    "seq_len = 512\n",
    "batch_size = 8\n",
    "learning_rate = 5e-5\n",
    "weight_decay = 0.0\n",
    "num_train_epochs = 1\n",
    "lr_scheduler_type = \"linear\"\n",
    "num_warmup_steps = 0\n",
    "eval_every_steps = 5\n",
    "k = int(512 * 0.3)\n",
    "\n",
    "# Flag to make \n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    logger.info(f\"Starting tokenizer training\")\n",
    "\n",
    "    logger.info(f\"Loading dataset\")\n",
    "\n",
    "    wandb.init(project=wandb_project) #Skipping config for now - will add back later\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    raw_datasets = load_dataset(dataset_name, dataset_version)\n",
    "\n",
    "    # Make a small dataset for proof of concept\n",
    "    if debug:\n",
    "        raw_datasets = utils.sample_small_debug_dataset(raw_datasets)\n",
    "\n",
    "    ## TOKENIZER\n",
    "    tokenizer = PegasusTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "    ## PRETRAINED MODEL\n",
    "    #The pegasus model is too large to test on a laptop, so load a small config for now\n",
    "    #model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "    config = PegasusConfig(\n",
    "            encoder_layers=2, \n",
    "            decoder_layers=2, \n",
    "            encoder_attention_heads=8, \n",
    "            decoder_attention_heads=8, \n",
    "            decoder_ffn_dim=1024, \n",
    "            encoder_ffn_dim=1024,\n",
    "            max_position_embeddings=seq_len,\n",
    "            vocab_size=tokenizer.vocab_size\n",
    "            )\n",
    "    model = PegasusForConditionalGeneration(config).to(device)\n",
    "\n",
    "    column_names = raw_datasets[\"train\"].column_names\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        inputs = [ex for ex in examples['article']]\n",
    "        targets = [ex for ex in examples['highlights']]\n",
    "        model_inputs = tokenizer(inputs, max_length=seq_len, truncation=True)\n",
    "        model_inputs['labels'] = tokenizer(targets, max_length=seq_len, truncation=True)['input_ids']\n",
    "        return model_inputs\n",
    "\n",
    "    tokenized_datasets = raw_datasets.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        num_proc=8,\n",
    "        remove_columns=column_names,\n",
    "        load_from_cache_file=True,\n",
    "        desc=\"Tokenizing the dataset\",\n",
    "    )\n",
    "\n",
    "    train_dataset = tokenized_datasets[\"train\"]\n",
    "    eval_dataset = tokenized_datasets[\"validation\"] if \"validaion\" in tokenized_datasets else tokenized_datasets[\"test\"]\n",
    "\n",
    "    for index in random.sample(range(len(train_dataset)), 2):\n",
    "        logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")\n",
    "        logger.info(f\"Sample {index} of the training set input ids: {train_dataset[index]['input_ids']}.\")\n",
    "        logger.info(f\"Decoded input_ids: {tokenizer.decode(train_dataset[index]['input_ids'])}\")\n",
    "        logger.info(f\"Decoded labels: {tokenizer.decode(train_dataset[index]['labels'])}\")\n",
    "        logger.info(\"\\n\")\n",
    "\n",
    "    #collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer, max_length=seq_len, padding='max_length')\n",
    "    collator = transformers.DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, max_length=seq_len, padding='max_length')\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, \n",
    "        shuffle=True, \n",
    "        collate_fn=collator, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    eval_dataloader = DataLoader(\n",
    "        eval_dataset, \n",
    "        collate_fn=collator, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "    \n",
    "    # Scheduler and math around the number of training steps.\n",
    "    num_update_steps_per_epoch = len(train_dataloader)\n",
    "    max_train_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "    lr_scheduler = transformers.get_scheduler(\n",
    "        name=lr_scheduler_type,\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=max_train_steps,\n",
    "    )\n",
    "\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
    "    logger.info(f\"  Num Epochs = {num_train_epochs}\")\n",
    "    logger.info(f\"  Total optimization steps = {max_train_steps}\")\n",
    "    progress_bar = tqdm(range(max_train_steps))\n",
    "\n",
    "    # Log a pre-processed training example to make sure the pre-processing does not have bugs in it\n",
    "    # and we do not input garbage to our model.\n",
    "    batch = next(iter(train_dataloader))\n",
    "\n",
    "    #logger.info(\"Look at the data that we input into the model, check that it looks like what we expect.\")\n",
    "    #for index in random.sample(range(len(batch)), 2):\n",
    "    #    logger.info(f\"Decoded input_ids size: {len(batch['input_ids'][index])}\")\n",
    "    #    logger.info(f\"Decoded input_ids: {tokenizer.decode(batch['input_ids'][index])}\")\n",
    "    #    logger.info(f\"Decoded labels size: {len(batch['labels'][index])}\")\n",
    "    #    logger.info(f\"Decoded labels: {tokenizer.decode(batch['labels'][index])}\")\n",
    "    #    logger.info(\"\\n\")\n",
    "\n",
    "    global_step = 0\n",
    "    for epoch in range(num_train_epochs):\n",
    "        model.train()\n",
    "        for batch in train_dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            out = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = out[\"loss\"]\n",
    "            logits = out[\"logits\"]\n",
    "            res = torch.topk(logits, k=k)\n",
    "            values = res[0]\n",
    "            #print(values)\n",
    "            #print(\"\\n\\n\")\n",
    "            #print(indices)\n",
    "\n",
    "            #print(loss.item())\n",
    "            #print(\"\\n\\n\")\n",
    "            #print(logits)\n",
    "            #print(\"\\n\\n\")\n",
    "            #print(labels)\n",
    "\n",
    "            #tokenizer.decode()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            global_step += 1\n",
    "\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"train_loss\": loss,\n",
    "                    \"learning_rate\": optimizer.param_groups[0][\"lr\"],\n",
    "                    \"epoch\": epoch,\n",
    "                },\n",
    "                step=global_step,\n",
    "            )\n",
    "\n",
    "            if (global_step % eval_every_steps == 0) or (global_step >= max_train_steps):\n",
    "                model.eval()\n",
    "\n",
    "                #TODO: USING SAME VALUE FOR PREDICTION AND REFERENCE!!!!\n",
    "                for text in labels:\n",
    "                    print(text)\n",
    "                    print(\"\\n\")\n",
    "                    print(text.item())\n",
    "                    print(\"\\n\\n\")\n",
    "                #    print( \"SUMMARY: \" + str(tokenizer.decode(text)))\n",
    "\n",
    "                rouge_score = rouge.compute(predictions=values, references=labels)\n",
    "\n",
    "                metric = {}\n",
    "                for rouge_type in rouge_score:\n",
    "                    metric['eval/' + rouge_type + \"/precision\"] = rouge_score[rouge_type][0][0]\n",
    "                    metric['eval/' + rouge_type + \"/recall\"] = rouge_score[rouge_type][0][1]\n",
    "                    metric['eval/' + rouge_type + \"/f1-score\"] = rouge_score[rouge_type][0][2]\n",
    "\n",
    "                wandb.log(metric, step=global_step)\n",
    "\n",
    "                logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "                model.save_pretrained(output_dir)\n",
    "\n",
    "                model.train()\n",
    "\n",
    "            if global_step >= max_train_steps:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2022 16:58:50 - INFO - Summarization - Starting tokenizer training\n",
      "04/21/2022 16:58:50 - INFO - Summarization - Loading dataset\n",
      "04/21/2022 16:58:50 - ERROR - wandb.jupyter - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mglemasurier\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/glemasurier/PegasusSummarization/runs/2fe1erey\" target=\"_blank\">valiant-energy-33</a></strong> to <a href=\"https://wandb.ai/glemasurier/PegasusSummarization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2022 16:58:54 - WARNING - datasets.builder - Reusing dataset cnn_dailymail (/home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n",
      "100%|██████████| 3/3 [00:00<00:00, 600.39it/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Tokenizing the dataset #0:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Tokenizing the dataset #2: 100%|██████████| 1/1 [00:00<00:00, 10.46ba/s]\n",
      "Tokenizing the dataset #4: 100%|██████████| 1/1 [00:00<00:00, 11.91ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tokenizing the dataset #0: 100%|██████████| 1/1 [00:00<00:00, 11.46ba/s]\n",
      "Tokenizing the dataset #1: 100%|██████████| 1/1 [00:00<00:00, 12.34ba/s]\n",
      "Tokenizing the dataset #3: 100%|██████████| 1/1 [00:00<00:00, 10.94ba/s]\n",
      "Tokenizing the dataset #7: 100%|██████████| 1/1 [00:00<00:00, 12.63ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tokenizing the dataset #5: 100%|██████████| 1/1 [00:00<00:00,  8.30ba/s]\n",
      "Tokenizing the dataset #6: 100%|██████████| 1/1 [00:00<00:00, 10.35ba/s]\n",
      "04/21/2022 16:59:03 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-d0a4db7e75848594.arrow\n",
      "04/21/2022 16:59:03 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-11368ed1919ef15e.arrow\n",
      "04/21/2022 16:59:03 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-41743d9c35ae7342.arrow\n",
      "04/21/2022 16:59:03 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-96c4c14420000a37.arrow\n",
      "04/21/2022 16:59:03 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-42b08a05ae844de5.arrow\n",
      "04/21/2022 16:59:03 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-2e96a0eb97e4ef07.arrow\n",
      "04/21/2022 16:59:03 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-34cf568132480bcb.arrow\n",
      "04/21/2022 16:59:03 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-325b2297b11dd577.arrow\n",
      "04/21/2022 16:59:04 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-d0a4db7e75848594.arrow\n",
      "04/21/2022 16:59:04 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-11368ed1919ef15e.arrow\n",
      "04/21/2022 16:59:04 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-41743d9c35ae7342.arrow\n",
      "04/21/2022 16:59:04 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-96c4c14420000a37.arrow\n",
      "04/21/2022 16:59:04 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-42b08a05ae844de5.arrow\n",
      "04/21/2022 16:59:04 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-2e96a0eb97e4ef07.arrow\n",
      "04/21/2022 16:59:04 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-34cf568132480bcb.arrow\n",
      "04/21/2022 16:59:04 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/greg/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-325b2297b11dd577.arrow\n",
      "04/21/2022 16:59:04 - INFO - Summarization - Sample 68 of the training set: {'input_ids': [5300, 131, 116, 5469, 112, 1713, 109, 34372, 34294, 3164, 117, 124, 109, 6412, 204, 2084, 160, 109, 849, 107, 5300, 127, 6674, 464, 9464, 108, 9284, 108, 2579, 108, 3397, 108, 9650, 111, 4027, 112, 1713, 109, 43456, 1311, 317, 1465, 111, 109, 787, 107, 343, 109, 5708, 690, 112, 109, 13241, 2967, 208, 24179, 48495, 3084, 108, 162, 140, 8728, 130, 109, 3164, 422, 111, 117, 136, 396, 2814, 109, 9379, 9120, 2207, 212, 133, 174, 7595, 314, 1225, 108, 122, 109, 3083, 113, 317, 19168, 111, 18458, 2115, 993, 112, 6681, 109, 2582, 107, 36582, 21071, 308, 112, 1183, 9379, 9120, 2207, 242, 305, 4461, 130, 60386, 1519, 9860, 110, 107, 31885, 15883, 3836, 893, 156, 113, 1873, 113, 2115, 124, 109, 13241, 2967, 208, 24179, 48495, 3084, 422, 124, 1789, 110, 107, 3473, 34776, 117, 115, 918, 115, 80294, 333, 109, 9379, 9120, 2207, 124, 109, 1489, 4015, 136, 396, 110, 107, 139, 9379, 1537, 5299, 108, 17090, 2619, 8538, 47310, 415, 14895, 2288, 108, 243, 124, 1789, 120, 114, 177, 422, 111, 2582, 138, 217, 112, 129, 836, 112, 4271, 109, 1702, 107, 139, 531, 117, 163, 2635, 114, 5469, 118, 109, 14568, 113, 109, 52024, 34294, 3164, 107, 402, 7699, 109, 575, 113, 2814, 109, 34294, 3164, 115, 34372, 117, 120, 109, 13241, 2967, 208, 24179, 422, 117, 114, 3831, 422, 111, 146, 638, 118, 114, 461, 2116, 3063, 4152, 172, 114, 34294, 3164, 132, 254, 114, 9379, 9120, 2207, 108, 123, 243, 90892, 32659, 54626, 108, 1276, 113, 109, 9379, 4691, 7925, 107, 402, 359, 119, 1748, 186, 117, 146, 156, 63585, 124, 109, 3063, 422, 136, 396, 111, 186, 117, 188, 220, 295, 118, 183, 640, 112, 109, 6205, 713, 113, 2115, 107, 402, 284, 133, 7123, 145, 192, 133, 112, 999, 308, 19168, 112, 23351, 2115, 111, 364, 172, 18458, 2115, 124, 109, 1091, 36999, 6004, 143, 2130, 109, 2906, 71579, 158, 188, 112, 193, 230, 118, 579, 120, 1168, 122, 2814, 114, 34294, 3164, 107, 2040, 20405, 386, 2858, 143, 26271, 268, 158, 1358, 1465, 112, 3669, 464, 109, 706, 1013, 115, 109, 34294, 3164, 115, 1338, 110, 107, 139, 455, 140, 886, 124, 109, 19524, 70076, 6004, 108, 162, 140, 5195, 118, 109, 43456, 71500, 110, 107, 402, 1199, 109, 2115, 127, 16240, 111, 3634, 111, 8641, 126, 192, 129, 3394, 112, 179, 4061, 112, 999, 183, 308, 107, 123, 285, 717, 151, 402, 284, 4324, 109, 34294, 3164, 138, 519, 5300, 317, 1061, 28036, 604, 13328, 112, 1713, 111, 145, 133, 1673, 150, 2386, 112, 461, 4152, 3063, 122, 109, 2814, 435, 136, 396, 113, 109, 9379, 9120, 2207, 107, 402, 1287, 230, 132, 372, 145, 138, 129, 2814, 109, 1489, 4015, 131, 116, 7608, 2879, 430, 30249, 233, 120, 138, 129, 109, 1061, 307, 4382, 113, 109, 4498, 113, 5300, 107, 402, 1435, 1106, 214, 372, 2899, 231, 111, 466, 122, 109, 6178, 4015, 455, 108, 145, 127, 506, 313, 112, 1178, 364, 172, 3109, 34490, 604, 13328, 124, 219, 11489, 107, 402, 812, 424, 122, 136, 2059, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [5300, 117, 14799, 112, 1713, 109, 34294, 3164, 118, 109, 211, 166, 115, 34372, 110, 107, 343, 5469, 117, 115, 2954, 640, 112, 9896, 656, 118, 1385, 2017, 110, 107, 13241, 2967, 208, 24179, 48495, 3084, 117, 2814, 9379, 9120, 2207, 136, 396, 110, 107, 343, 422, 192, 1085, 1124, 1586, 113, 2998, 2115, 2515, 112, 1713, 34294, 3164, 110, 107, 5300, 117, 2635, 5469, 115, 52024, 124, 114, 1396, 121, 9394, 422, 110, 107, 1]}.\n",
      "04/21/2022 16:59:04 - INFO - Summarization - Sample 68 of the training set input ids: [5300, 131, 116, 5469, 112, 1713, 109, 34372, 34294, 3164, 117, 124, 109, 6412, 204, 2084, 160, 109, 849, 107, 5300, 127, 6674, 464, 9464, 108, 9284, 108, 2579, 108, 3397, 108, 9650, 111, 4027, 112, 1713, 109, 43456, 1311, 317, 1465, 111, 109, 787, 107, 343, 109, 5708, 690, 112, 109, 13241, 2967, 208, 24179, 48495, 3084, 108, 162, 140, 8728, 130, 109, 3164, 422, 111, 117, 136, 396, 2814, 109, 9379, 9120, 2207, 212, 133, 174, 7595, 314, 1225, 108, 122, 109, 3083, 113, 317, 19168, 111, 18458, 2115, 993, 112, 6681, 109, 2582, 107, 36582, 21071, 308, 112, 1183, 9379, 9120, 2207, 242, 305, 4461, 130, 60386, 1519, 9860, 110, 107, 31885, 15883, 3836, 893, 156, 113, 1873, 113, 2115, 124, 109, 13241, 2967, 208, 24179, 48495, 3084, 422, 124, 1789, 110, 107, 3473, 34776, 117, 115, 918, 115, 80294, 333, 109, 9379, 9120, 2207, 124, 109, 1489, 4015, 136, 396, 110, 107, 139, 9379, 1537, 5299, 108, 17090, 2619, 8538, 47310, 415, 14895, 2288, 108, 243, 124, 1789, 120, 114, 177, 422, 111, 2582, 138, 217, 112, 129, 836, 112, 4271, 109, 1702, 107, 139, 531, 117, 163, 2635, 114, 5469, 118, 109, 14568, 113, 109, 52024, 34294, 3164, 107, 402, 7699, 109, 575, 113, 2814, 109, 34294, 3164, 115, 34372, 117, 120, 109, 13241, 2967, 208, 24179, 422, 117, 114, 3831, 422, 111, 146, 638, 118, 114, 461, 2116, 3063, 4152, 172, 114, 34294, 3164, 132, 254, 114, 9379, 9120, 2207, 108, 123, 243, 90892, 32659, 54626, 108, 1276, 113, 109, 9379, 4691, 7925, 107, 402, 359, 119, 1748, 186, 117, 146, 156, 63585, 124, 109, 3063, 422, 136, 396, 111, 186, 117, 188, 220, 295, 118, 183, 640, 112, 109, 6205, 713, 113, 2115, 107, 402, 284, 133, 7123, 145, 192, 133, 112, 999, 308, 19168, 112, 23351, 2115, 111, 364, 172, 18458, 2115, 124, 109, 1091, 36999, 6004, 143, 2130, 109, 2906, 71579, 158, 188, 112, 193, 230, 118, 579, 120, 1168, 122, 2814, 114, 34294, 3164, 107, 2040, 20405, 386, 2858, 143, 26271, 268, 158, 1358, 1465, 112, 3669, 464, 109, 706, 1013, 115, 109, 34294, 3164, 115, 1338, 110, 107, 139, 455, 140, 886, 124, 109, 19524, 70076, 6004, 108, 162, 140, 5195, 118, 109, 43456, 71500, 110, 107, 402, 1199, 109, 2115, 127, 16240, 111, 3634, 111, 8641, 126, 192, 129, 3394, 112, 179, 4061, 112, 999, 183, 308, 107, 123, 285, 717, 151, 402, 284, 4324, 109, 34294, 3164, 138, 519, 5300, 317, 1061, 28036, 604, 13328, 112, 1713, 111, 145, 133, 1673, 150, 2386, 112, 461, 4152, 3063, 122, 109, 2814, 435, 136, 396, 113, 109, 9379, 9120, 2207, 107, 402, 1287, 230, 132, 372, 145, 138, 129, 2814, 109, 1489, 4015, 131, 116, 7608, 2879, 430, 30249, 233, 120, 138, 129, 109, 1061, 307, 4382, 113, 109, 4498, 113, 5300, 107, 402, 1435, 1106, 214, 372, 2899, 231, 111, 466, 122, 109, 6178, 4015, 455, 108, 145, 127, 506, 313, 112, 1178, 364, 172, 3109, 34490, 604, 13328, 124, 219, 11489, 107, 402, 812, 424, 122, 136, 2059, 1].\n",
      "04/21/2022 16:59:04 - INFO - Summarization - Decoded input_ids: Turkey's bid to host the 2022 Ryder Cup is on the rocks over concerns about the environment. Turkey are competing against Austria, Denmark, Germany, Italy, Portugal and Spain to host the biennial match between Europe and the US. But the developments needed to the Montgomerie Maxx Royal, which was nominated as the Cup course and is this week hosting the Turkish Airlines Open – have been deemed too significant, with the removal of between 6,000 and 15,000 trees necessary to modify the infrastructure. VIDEO Scroll down to watch Turkish Airlines Open day 1 highlights as Jimenez cards 63. Sergio Garcia stuck behind one of thousands of trees on the Montgomerie Maxx Royal course on Thursday. Lee Westwood is in action in Antalya during the Turkish Airlines Open on the European Tour this week. The Turkish sports minister, Akif Cagatay Kilic, said on Thursday that a new course and infrastructure will need to be built to accommodate the competition. The country is also considering a bid for the staging of the 2026 Ryder Cup. ‘Unfortunately the problem of hosting the Ryder Cup in 2022 is that the Montgomerie course is a resort course and not designed for a big scale golf tournament like a Ryder Cup or even a Turkish Airlines Open,’ said Ahmet Agaoglu, President of the Turkish Golf Federation. ‘If you notice there is not one grandstand on the golf course this week and there is just no place for them due to the enormous amount of trees. ‘We have calculated we would have to cut down 6,000 to 7,000 trees and something like 15,000 trees on the Faldo Course (at the nearby Cornelia) just to make way for everything that goes with hosting a Ryder Cup. Paul McGinley (centre right) led Europe to victory against the United States in the Ryder Cup in September. The event was held on the PGA Centenary Course, which was modified for the biennial showpiece. ‘All the trees are numbered and licensed and environmentally it would be impossible to get permission to cut them down.’ He added: ‘We estimate the Ryder Cup will cost Turkey between 100-200 million euros to host and we have shown our commitment to big tournament golf with the hosting again this week of the Turkish Airlines Open. ‘One way or another we will be hosting the European Tour's Final Series until 2023 - that will be the 100th anniversary of the Republic of Turkey. ‘That gives us another nine years and along with the Challenge Tour event, we are already going to spend something like 70-85 million euros on these tournaments. ‘So together with this continued\n",
      "04/21/2022 16:59:04 - INFO - Summarization - Decoded labels: Turkey is bidding to host the Ryder Cup for the first time in 2022. But bid is in trouble due to modifications required for existing courses. Montgomerie Maxx Royal is hosting Turkish Airlines Open this week. But course would require huge numbers of protected trees removed to host Ryder Cup. Turkey is considering bid in 2026 on a purpose-built course.\n",
      "04/21/2022 16:59:04 - INFO - Summarization - \n",
      "\n",
      "04/21/2022 16:59:04 - INFO - Summarization - Sample 3 of the training set: {'input_ids': [143, 40155, 158, 1315, 35443, 45475, 67346, 116, 34644, 116, 517, 9240, 122, 6328, 111, 2477, 121, 7762, 2511, 107, 5060, 131, 116, 2178, 3285, 117, 156, 113, 35443, 45475, 67346, 116, 131, 909, 7021, 107, 24485, 118, 109, 5393, 16877, 7243, 115, 8497, 109, 6015, 7590, 140, 1729, 156, 113, 198, 159, 894, 131, 116, 1386, 77176, 2184, 194, 141, 2247, 3287, 107, 15153, 112, 109, 729, 1847, 108, 169, 2511, 127, 146, 4304, 112, 193, 114, 1736, 107, 198, 284, 1373, 126, 140, 221, 356, 118, 142, 6330, 172, 16877, 112, 193, 203, 2210, 1373, 401, 413, 3210, 114, 501, 111, 112, 4466, 114, 501, 108, 120, 117, 109, 674, 474, 745, 178, 898, 11869, 134, 109, 1671, 113, 169, 198, 38897, 420, 194, 563, 115, 18292, 108, 793, 4611, 107, 45475, 67346, 116, 18481, 120, 109, 582, 1500, 2354, 117, 146, 1533, 11123, 112, 461, 111, 4964, 6043, 1017, 108, 155, 135, 26785, 472, 4039, 107, 198, 31446, 186, 195, 114, 344, 113, 844, 120, 145, 947, 124, 414, 124, 1137, 108, 155, 124, 109, 176, 561, 878, 341, 195, 163, 16158, 262, 109, 469, 113, 1187, 117, 509, 167, 2086, 496, 4987, 219, 177, 5384, 178, 2085, 11865, 120, 169, 5948, 138, 801, 112, 26450, 111, 129, 1862, 108, 198, 10474, 126, 495, 660, 113, 1934, 108, 155, 154, 1482, 111, 660, 113, 1154, 341, 108, 660, 113, 985, 112, 108, 146, 4213, 122, 12418, 108, 155, 154, 2064, 112, 1378, 111, 112, 109, 525, 278, 496, 1006, 2511, 133, 7814, 2586, 10022, 111, 634, 45475, 67346, 116, 1847, 114, 515, 113, 3964, 121, 89458, 1932, 107, 4327, 45475, 67346, 116, 309, 2618, 114, 1083, 113, 70919, 270, 11559, 114, 198, 7808, 75207, 496, 198, 187, 311, 126, 131, 116, 114, 442, 120, 117, 589, 55812, 112, 109, 3404, 2198, 113, 200, 126, 117, 2140, 112, 107, 325, 126, 288, 117, 114, 660, 113, 1488, 1286, 120, 118, 878, 658, 117, 356, 262, 157, 207, 2187, 9855, 107, 600, 715, 117, 120, 224, 109, 582, 6615, 120, 1560, 138, 5317, 86600, 111, 10966, 745, 178, 243, 107, 285, 3999, 120, 141, 270, 350, 112, 2847, 112, 291, 4110, 3105, 117, 8614, 190, 364, 177, 107, 198, 362, 117, 146, 433, 112, 498, 115, 136, 779, 175, 119, 272, 131, 144, 133, 114, 1083, 113, 223, 33138, 3062, 745, 178, 243, 107, 198, 3821, 563, 148, 112, 129, 585, 108, 155, 2086, 111, 991, 108, 155, 126, 289, 116, 3689, 107, 485, 117, 506, 142, 2462, 2221, 113, 7017, 33138, 4110, 107, 412, 2816, 108, 125, 131, 208, 1264, 1850, 33138, 465, 108, 155, 125, 2966, 115, 221, 33138, 488, 496, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [6015, 7590, 117, 1392, 1937, 893, 11023, 2511, 482, 109, 278, 110, 107, 8497, 131, 116, 16877, 563, 111, 5060, 131, 116, 2178, 3285, 127, 228, 4964, 2724, 110, 107, 45475, 67346, 116, 24753, 47535, 115, 114, 405, 111, 1392, 121, 17615, 16885, 110, 107, 1]}.\n",
      "04/21/2022 16:59:04 - INFO - Summarization - Sample 3 of the training set input ids: [143, 40155, 158, 1315, 35443, 45475, 67346, 116, 34644, 116, 517, 9240, 122, 6328, 111, 2477, 121, 7762, 2511, 107, 5060, 131, 116, 2178, 3285, 117, 156, 113, 35443, 45475, 67346, 116, 131, 909, 7021, 107, 24485, 118, 109, 5393, 16877, 7243, 115, 8497, 109, 6015, 7590, 140, 1729, 156, 113, 198, 159, 894, 131, 116, 1386, 77176, 2184, 194, 141, 2247, 3287, 107, 15153, 112, 109, 729, 1847, 108, 169, 2511, 127, 146, 4304, 112, 193, 114, 1736, 107, 198, 284, 1373, 126, 140, 221, 356, 118, 142, 6330, 172, 16877, 112, 193, 203, 2210, 1373, 401, 413, 3210, 114, 501, 111, 112, 4466, 114, 501, 108, 120, 117, 109, 674, 474, 745, 178, 898, 11869, 134, 109, 1671, 113, 169, 198, 38897, 420, 194, 563, 115, 18292, 108, 793, 4611, 107, 45475, 67346, 116, 18481, 120, 109, 582, 1500, 2354, 117, 146, 1533, 11123, 112, 461, 111, 4964, 6043, 1017, 108, 155, 135, 26785, 472, 4039, 107, 198, 31446, 186, 195, 114, 344, 113, 844, 120, 145, 947, 124, 414, 124, 1137, 108, 155, 124, 109, 176, 561, 878, 341, 195, 163, 16158, 262, 109, 469, 113, 1187, 117, 509, 167, 2086, 496, 4987, 219, 177, 5384, 178, 2085, 11865, 120, 169, 5948, 138, 801, 112, 26450, 111, 129, 1862, 108, 198, 10474, 126, 495, 660, 113, 1934, 108, 155, 154, 1482, 111, 660, 113, 1154, 341, 108, 660, 113, 985, 112, 108, 146, 4213, 122, 12418, 108, 155, 154, 2064, 112, 1378, 111, 112, 109, 525, 278, 496, 1006, 2511, 133, 7814, 2586, 10022, 111, 634, 45475, 67346, 116, 1847, 114, 515, 113, 3964, 121, 89458, 1932, 107, 4327, 45475, 67346, 116, 309, 2618, 114, 1083, 113, 70919, 270, 11559, 114, 198, 7808, 75207, 496, 198, 187, 311, 126, 131, 116, 114, 442, 120, 117, 589, 55812, 112, 109, 3404, 2198, 113, 200, 126, 117, 2140, 112, 107, 325, 126, 288, 117, 114, 660, 113, 1488, 1286, 120, 118, 878, 658, 117, 356, 262, 157, 207, 2187, 9855, 107, 600, 715, 117, 120, 224, 109, 582, 6615, 120, 1560, 138, 5317, 86600, 111, 10966, 745, 178, 243, 107, 285, 3999, 120, 141, 270, 350, 112, 2847, 112, 291, 4110, 3105, 117, 8614, 190, 364, 177, 107, 198, 362, 117, 146, 433, 112, 498, 115, 136, 779, 175, 119, 272, 131, 144, 133, 114, 1083, 113, 223, 33138, 3062, 745, 178, 243, 107, 198, 3821, 563, 148, 112, 129, 585, 108, 155, 2086, 111, 991, 108, 155, 126, 289, 116, 3689, 107, 485, 117, 506, 142, 2462, 2221, 113, 7017, 33138, 4110, 107, 412, 2816, 108, 125, 131, 208, 1264, 1850, 33138, 465, 108, 155, 125, 2966, 115, 221, 33138, 488, 496, 1].\n",
      "04/21/2022 16:59:04 - INFO - Summarization - Decoded input_ids: (CNN) -- Rem Koolhaas revolutionizes city landscapes with distinctive and cutting-edge buildings. Seattle's Central Library is one of Rem Koolhaas' recent builds. Responsible for the iconic CCTV headquarters in Beijing the Dutch architect was named one of \"The World's Most Influential People\" by Time magazine. Similar to the man himself, his buildings are not afraid to make a statement. \"We felt it was very important for an entity like CCTV to make its presence felt... To generate a space and to define a space, that is the main thing,\" he told CNN at the opening of his \"Transformer\" building in Seoul, South Korea. Koolhaas admits that the current economic climate is not particularly favorable to big and bold architectural plans, but from adversity comes creativity. \"Definitely there were a number of projects that we worked on put on hold, but on the other hand certain things were also accelerated because the price of construction is getting so cheap.\" Despite these new parameters he remains optimistic that his profession will continue to invent and be relevant, \"because it means kind of smaller, but more complex and kind of interesting things, kind of related to, not necessarily with commerce, but more connected to culture and to the social world.\" His buildings have attracted worldwide fame and given Koolhaas himself a form of semi-celebrity status. Yet Koolhaas still feels a sense of unease being labeled a \"Starchitect.\" \"I think it's a name that is actually degrading to the vast majority of people it is applied to. And it really is a kind of political term that for certain clients is important because they use star architects. My hope is that through the current complexity that title will exit discretely and disappear,\" he said. He believes that by being able to respond to different demands architecture is evolving into something new. \"It is not possible to live in this age if you don't have a sense of many contradictory forces,\" he said. \"Each building has to be beautiful, but cheap and fast, but it lasts forever. That is already an incredible battery of seemingly contradictory demands. So yes, I'm definitely perhaps contradictory person, but I operate in very contradictory times.\"\n",
      "04/21/2022 16:59:04 - INFO - Summarization - Decoded labels: Dutch architect is creative force behind landmark buildings across the world. Beijing's CCTV building and Seattle's Central Library are two bold examples. Koolhaas embraces contradictions in a project and creative-commercial tensions.\n",
      "04/21/2022 16:59:04 - INFO - Summarization - \n",
      "\n",
      "04/21/2022 16:59:04 - INFO - Summarization - ***** Running training *****\n",
      "04/21/2022 16:59:04 - INFO - Summarization -   Num examples = 100\n",
      "04/21/2022 16:59:04 - INFO - Summarization -   Num Epochs = 1\n",
      "04/21/2022 16:59:04 - INFO - Summarization -   Total optimization steps = 13\n",
      " 38%|███▊      | 5/13 [00:20<00:32,  4.03s/it]04/21/2022 16:59:24 - INFO - Summarization - Saving model checkpoint to output_dir/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([33116,  7716,   112,  2094, 13966,  7414,   124,  1408,  1428,   115,\n",
      "         4600,  4354,   110,   107,  7716,  1155,   114,  1082,   124,  2277,\n",
      "          113,   342,   458,   114,  4235,   110,   107,   240,   178, 10074,\n",
      "         7414,   108,   178,   131,   267,  1762, 37362, 53729,   132, 20340,\n",
      "        53132,   110,   107,     1,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n",
      "tensor([43086,  7784,   133,   174,  1749,  1537, 17518,  1573,   113,   177,\n",
      "          578,   110,   107,  9493, 24106,  8990,  5908, 90937,   112,  4149,\n",
      "          112,  6235,  2493,   289,  1286,   110,   107, 43086,  3951,   299,\n",
      "          177,   578,   464,  8969,   134, 28879, 18460,   124,  1491,   565,\n",
      "          110,   107,     1,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n",
      "tensor([ 1763, 85104,   117, 11544,   244,   478,   197,   114,   232,   115,\n",
      "         1395,   113,  1188,  3867,  1560, 20693,   110,   107,   139, 38533,\n",
      "          140,  3190, 14601,   141, 16236,  2031,  5296, 16746,   110,   107,\n",
      "        85104,   131,   706, 15423,   112,  1073,   307,  3867,  6714,   464,\n",
      "          169,  1319,  1666, 32342,   124,  1342,   110,   107,   706,   138,\n",
      "          146,  1048,   115,  1489,  9607,  2493,   118,   211,   166,   381,\n",
      "        10349,   110,   107,     1,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n",
      "tensor([15452,  4103, 58054,  1152, 31298,   140,   374, 18193,   115,   169,\n",
      "         1119,   131, 27692,   108,  1310,   108,   238,   122, 13124,  6345,\n",
      "          279,   169,  3464,   110,   107,  7171,   196,   898,   169,  2936,\n",
      "          178,   140,   313,   112,  4330,  1847,   108,   162,   109,  1914,\n",
      "         2955,   635,   112,   129,   114,  9337,   110,   107, 15452,  4103,\n",
      "          131,   116,  1802,  3999,   169,  1601,   140,   847,   112, 18050,\n",
      "          364,   178,   196,   684,   124,  1180,   173,   178,   419, 52083,\n",
      "          132,  3175,   110,   107,  3385,  8258, 10081,  1019,   121,  1623,\n",
      "          131,   116,  1323,   142,  2648,   110,   107,     1,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n",
      "tensor([  982,  2040,  1091, 25765,   116,   116,  2342,  1327,   135,  7923,\n",
      "         1034,  8109,   178,   140,  1194,   141,   114,   439,   131,   285,\n",
      "        20656,  6020,   115, 10349,   112,  5130,   109,  3363,   124,   114,\n",
      "         2561,   238,   169,  2045,   263,   130,   109,  7243,   118,   215,\n",
      "        55257,  2702,   110,   107,   285,   140, 15293,   112,   296,   231,\n",
      "        17776,   108,   427,   292,   111,   114, 19653,  1226,   110,   107,\n",
      "          139,  5636,   404,   131,   116,  2214,   140,   606,   118, 13125,\n",
      "        75415,   110,   107,   285,  7789,  2336, 30343,   131,   116,  2045,\n",
      "        64421,   110,   107,     1,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n",
      "tensor([ 2508,   894,  1981,  2751, 46077,   116,  5372,   228,  1567,  2971,\n",
      "          115,   109,  7175,   113,  3064,   110,   107,   614,   117,   114,\n",
      "         2546,   475,   121, 18625,   120, 29280,   142,   655, 32136,   110,\n",
      "          107, 27633, 29280,   160,  1149,   655,  6293,   115,   109,  7175,\n",
      "          333,   109,  1795,   110,   107, 26073, 34458, 71101,  3047, 27232,\n",
      "          115,  1307,   112,   543,   154,   160, 20577,  4077,   110,   107,\n",
      "            1,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n",
      "tensor([14783, 27700,   134,  5581,   502,  4525,   109,  2101,   113,   695,\n",
      "          121, 13860, 81824,  5978,   303,   114,   958,   431,   112,  6595,\n",
      "         5777,   852,   115,  5099,   110,   107,   322,   133,  3087,  2571,\n",
      "         1412,  2047,   172,  1034, 26743,   131,   108,  1034,  6092,   131,\n",
      "          108,  1034, 12446,   131,   111,  1034,  6092, 12446,   131,   507,\n",
      "          127,  2211,   112,  1449,   109,  4526,   113,   989,   111,  9294,\n",
      "          110,   107,   139,  2995,  3087,  5057,  2101,   118,  1034, 34844,\n",
      "        49966,   131,   108,  1034, 71255,   131,   132,  1034, 66168,   131,\n",
      "          507,   127,   432,  1734,   141,   114,   443,   120,  5002,   180,\n",
      "          109, 34239,   117,   557,   110,   107, 21265,   416,   126,   256,\n",
      "          225,  2599,   199,   883,  1261,   211,  1184,   110,   107,     1])\n",
      "tensor([11989,   133,  2962,   109, 50763,   641,   120,  1857, 30913,   382,\n",
      "          129, 82962,   141,   109,  9941,   110,   107, 27494,  3047,   134,\n",
      "        85402,   115, 12827,   108,  7317,   110,   107,     1,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 10/13 [00:42<00:12,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7026,   121, 91462, 56816,   123,   116,  3669,  2120,   342,   164,\n",
      "          110,   107,   112,   129,  1276,   113,  2481,   115,  1326,   233,\n",
      "          173,   178,   117,   770,   112,   275,   693,   121,   497,   121,\n",
      "         4801,   110,   107,   122, 42785, 74721,   110,   107, 56816,  2737,\n",
      "          169,   571,   154,  6568,   110,   107,  8379, 42785, 11065,   661,\n",
      "          141,   371, 79483,   446,  2978,   113,   114,  9485,  2974,   110,\n",
      "          107,  4064, 23963,   549,   113,   109,   475,  6719,   829,   110,\n",
      "          107,     1,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n",
      "tensor([ 6015,  7590,   117,  1392,  1937,   893, 11023,  2511,   482,   109,\n",
      "          278,   110,   107,  8497,   131,   116, 16877,   563,   111,  5060,\n",
      "          131,   116,  2178,  3285,   127,   228,  4964,  2724,   110,   107,\n",
      "        45475, 67346,   116, 24753, 47535,   115,   114,   405,   111,  1392,\n",
      "          121, 17615, 16885,   110,   107,     1,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n",
      "tensor([23164,  1551,  9238,   148,  5464, 82776,   131,   116,  8388,   111,\n",
      "        16673, 33976,   110,   107,   139, 15965,  1019,   121,  1623,   131,\n",
      "          116,   769, 28197,   116,   111, 19492,   116,   164, 26132,   215,\n",
      "         1815,   110,   107,  1911,  5570,   795,  1490,   111,   221,  6409,\n",
      "          173,  4200,   112,   580,  4374,   110,   107,   452,   148,   112,\n",
      "         1178,   339,   539,   114,   242, 59617,   111,  6108,   215,   769,\n",
      "          110,   107,   452,   163,   148,   112,  1565,  8368,  2659,   112,\n",
      "          376,   215,  1233,  1515,   110,   107,     1,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n",
      "tensor([ 5300,   117, 14799,   112,  1713,   109, 34294,  3164,   118,   109,\n",
      "          211,   166,   115, 34372,   110,   107,   343,  5469,   117,   115,\n",
      "         2954,   640,   112,  9896,   656,   118,  1385,  2017,   110,   107,\n",
      "        13241,  2967,   208, 24179, 48495,  3084,   117,  2814,  9379,  9120,\n",
      "         2207,   136,   396,   110,   107,   343,   422,   192,  1085,  1124,\n",
      "         1586,   113,  2998,  2115,  2515,   112,  1713, 34294,  3164,   110,\n",
      "          107,  5300,   117,  2635,  5469,   115, 52024,   124,   114,  1396,\n",
      "          121,  9394,   422,   110,   107,     1,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n",
      "tensor([16213, 73866,  4759, 13946,   109,  8536,   115,  2822,  3287,   949,\n",
      "          110,   107, 45562,   810,   121,   526,   121,  7479,  1055,   133,\n",
      "          174,  8668,   190,   114,   410,   110,   107,  6096,   121, 29944,\n",
      "         9259,  1316, 54669,   111,  4185,  1157,   790,   274, 13073,   110,\n",
      "          107,     1,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n",
      "tensor([ 3535,  3073, 45342,   672,  2282,   115, 45323,   108,   351,  3477,\n",
      "          108,   124,  1789,   110,   107,   322, 45342,   109,   238,   113,\n",
      "          109,   517,   131,   116, 10601,   108,   169,  2936,   111,   114,\n",
      "         1541, 14853,  1900,   110,   107,   168,   140,   146,  1501,   786,\n",
      "          447,   109, 27495,   195,  3047,   111,  3740,  7955,   112, 10610,\n",
      "          110,   107,  6781,  6061, 20846,   649,   178,   148,   198,  2957,\n",
      "        16583,   109,   481,  1650,   115,   189,   230,   194,     1,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n",
      "tensor([  654,   109,   779,   113,  1925, 13473,   184,   551, 47933,   110,\n",
      "        10009,  4105,  8226,  1746,   115,  9641,   208,  3590,  4660,   110,\n",
      "          107,   184,   551, 47933, 16849,   114,  1146, 48490,   173,   178,\n",
      "          140, 30374,  7194,   118,   109, 26586,   110,   107, 20542,   169,\n",
      "          271,   113,  3590,  4843,   377,   111,   117,   156,   113,  4329,\n",
      "          131,   116,   205, 17451, 57978,   110,   107,  8260,   151,   202,\n",
      "        17451,   111,  1147, 38134,  1843,  8134,  1422,   342,   114,  1034,\n",
      "        42087,   131,  1032,  7801,   178,   148,  6305,   112,   177, 65117,\n",
      "          111,   117,  2931,   701,  7194,   166,   110,   107,     1])\n",
      "tensor([ 8407,  4957, 50187,   108,  3925,   108,  2145, 70822,  1303,   110,\n",
      "          107,     1,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2022 16:59:47 - INFO - Summarization - Saving model checkpoint to output_dir/\n",
      "100%|██████████| 13/13 [00:56<00:00,  4.22s/it]04/21/2022 17:00:00 - INFO - Summarization - Saving model checkpoint to output_dir/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5759,  1167,   304,  1846, 23999,   464,  8320,   819, 15225,   131,\n",
      "         1323,  1372,   110,   107, 27330,   113,   335,  1034, 21365,   116,\n",
      "         5222,   135,  1532,   406,   112,   813, 10255,   131,   222,  1185,\n",
      "         5539,  2662,  2365,   211,  1034, 11182,  3959,   131,   118,  3880,\n",
      "          110,   107,  2503,  3921,   112,   403,  1044,   199,   210, 33136,\n",
      "          116,  1798,   464,  6949,   110,   107,     1,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100])\n",
      "tensor([ 2471,   113,  5137, 36267,  6381,  1084,  1775,  1424,   112,   179,\n",
      "          896,  9390,   110,   107,  1006,  1601, 21561,  1084,  1775,   635,\n",
      "         1165,  4873,   111, 19440,   112, 42851,   116,   110,   107, 18119,\n",
      "         1758,  2346, 79297,   243,  3148, 36624,   140,   146,  7360,   110,\n",
      "          107,  6158,   374,   115,  1816,  1726,   113,  4603, 32053,   143,\n",
      "          788, 57454,   158,  8740,   110,   107,     1,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100])\n",
      "tensor([ 8896,  2365,   112,   354,   109,  5373,   805,   113,   109,  8505,\n",
      "        15298,  7166,   110,   107,   139,  3991,   138,  1048,   124,   109,\n",
      "         1034, 18057,   131,   477,   130,   122,   149,   926,  6840,   110,\n",
      "          107, 18858,   649,  2269,   354,   138,   129,   115,  3734,   113,\n",
      "          200,   131,   116,  6716,   110,   107,   436,  5304,   355,   129,\n",
      "         3514,   112,   109,  3084, 12676,   141,  1350,   677,   136,   232,\n",
      "          110,   107,     1])\n",
      "tensor([ 2184,   170, 10911,   118,   114, 14272,  1174,  1066,   127,  1542,\n",
      "         1081,   113,   153, 60068,   121, 10461, 15868,   110,   107,  1027,\n",
      "        14929,  1174,  2115,   165,   113,  3053,  5721,   111,   518, 32364,\n",
      "          165,   118,   109, 34748,  9041, 11441,   375,   110,   107,  8858,\n",
      "        55708,   109,  3585,   115,  3226,  5641,   111, 11733,   316,   124,\n",
      "          114, 16806, 84985,  1088,   113,  1113,  8508,   111, 12012,   110,\n",
      "          107,     1,  -100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:58<00:00,  4.49s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    if version.parse(datasets.__version__) < version.parse(\"1.18.0\"):\n",
    "        raise RuntimeError(\"This script requires Datasets 1.18.0 or higher. Please update via pip install -U datasets.\")\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78a98554bd959fe647588642884065a24bb8267d1904c1c950aa6b68cc3632ad"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('nlp_class')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
