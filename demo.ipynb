{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages/paramiko/transport.py:236: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n",
      "/home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages/gradio/interface.py:383: UserWarning: The `allow_flagging` parameter in `Interface` nowtakes a string value ('auto', 'manual', or 'never'), not a boolean. Setting parameter to: 'never'.\n",
      "  \"The `allow_flagging` parameter in `Interface` now\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7861/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f07a5a34cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<fastapi.applications.FastAPI at 0x7f0842f05f10>,\n",
       " 'http://127.0.0.1:7861/',\n",
       " None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import torch\n",
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration, PegasusConfig\n",
    "from numba import cuda\n",
    "\n",
    "if torch.cuda.is_available:\n",
    "    torch.cuda.empty_cache()\n",
    "cuda_device = cuda.get_current_device()\n",
    "cuda_device.reset()\n",
    "\n",
    "device = 'cpu'#'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-xsum')\n",
    "\n",
    "config = PegasusConfig.from_json_file(os.path.join(\"./\", \"pretrained_config.json\"))\n",
    "model = PegasusForConditionalGeneration(config).to(device)\n",
    "state_dict = torch.load(os.path.join(\"./\", \"pretrained_model.bin\"))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "def process(src):\n",
    "    tokenized_src = tokenizer(src,return_tensors=\"pt\")[\"input_ids\"]\n",
    "    tokenized_summary = model.generate(tokenized_src)\n",
    "    summary = tokenizer.batch_decode(tokenized_summary, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    return summary[0]\n",
    "\n",
    "demo = gr.Interface(fn=process, inputs=\"text\", outputs=\"text\", allow_flagging = False)\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78a98554bd959fe647588642884065a24bb8267d1904c1c950aa6b68cc3632ad"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('nlp_class')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
