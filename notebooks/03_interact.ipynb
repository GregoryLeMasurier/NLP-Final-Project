{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformer_mt.modeling_transformer import TransfomerEncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/greg/miniconda3/envs/nlp_class/lib/python3.7/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# You probably need to modify the paths to your tokenizers\n",
    "# For tokenizers, you need to provide the path to a directory that contains the tokenizer.json file\n",
    "# For model, you need to provide the path to a directory that contains the model.pt file\n",
    "\n",
    "source_tokenizer = PreTrainedTokenizerFast.from_pretrained(\"../en_de_output_dir/en_tokenizer\")\n",
    "target_tokenizer = PreTrainedTokenizerFast.from_pretrained(\"../en_de_output_dir/de_tokenizer\")\n",
    "\n",
    "model = TransfomerEncoderDecoderModel.from_pretrained(\"../en_de_output_dir\")\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Try out your model. Feel free to use your own sentences and to compare the model outputs to Google Translate.\n",
    "Find at least three sentences that are translated well, and one that is translated badly.\n",
    "\n",
    "Feel free to change beam size and max_length parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The one below does not translate well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Der Tee ist fast leer.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This was one of the worst translations I google translate says the result means: \n",
    "# \"The tea is almost empty\" which is very close but not exact\n",
    "input_ids = source_tokenizer.encode(\"My iced tea is almost empty.\", return_tensors=\"pt\")\n",
    "output_ids = model.generate(\n",
    "    input_ids,\n",
    "    max_length=10,\n",
    "    bos_token_id=target_tokenizer.bos_token_id,\n",
    "    eos_token_id=target_tokenizer.eos_token_id,\n",
    "    pad_token_id=target_tokenizer.pad_token_id,\n",
    ")\n",
    "target_tokenizer.decode(output_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The two below translate pretty well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ich weiß nicht, ob dieser Satz gut übersetzen wird'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = source_tokenizer.encode(\"I do not know if this sentence will translate well.\", return_tensors=\"pt\")\n",
    "output_ids = model.generate(\n",
    "    input_ids,\n",
    "    max_length=10,\n",
    "    bos_token_id=target_tokenizer.bos_token_id,\n",
    "    eos_token_id=target_tokenizer.eos_token_id,\n",
    "    pad_token_id=target_tokenizer.pad_token_id,\n",
    ")\n",
    "target_tokenizer.decode(output_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Es ist schwer, das Modell ver wechseln.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = source_tokenizer.encode(\"It is hard to confuse the model.\", return_tensors=\"pt\")\n",
    "output_ids = model.generate(\n",
    "    input_ids,\n",
    "    max_length=10,\n",
    "    bos_token_id=target_tokenizer.bos_token_id,\n",
    "    eos_token_id=target_tokenizer.eos_token_id,\n",
    "    pad_token_id=target_tokenizer.pad_token_id,\n",
    ")\n",
    "target_tokenizer.decode(output_ids[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f86d5ac646110a331c60478f9400a1a64d0cd523be90d887457228f9723636b5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('nlp_class')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
